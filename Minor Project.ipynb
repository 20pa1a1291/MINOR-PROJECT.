{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69cb45ff",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING MODEL TO PREDICT THE GENDER BASED ON VOICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1fa2e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1206e90e",
   "metadata": {},
   "source": [
    "## IMPORT DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bdb4862e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0  0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1  0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2  0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3  0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4  0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0   274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1   634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2  1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3     4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4     4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "\n",
       "     maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0  0.275862  0.007812  0.007812  0.007812  0.000000  0.000000   male  \n",
       "1  0.250000  0.009014  0.007812  0.054688  0.046875  0.052632   male  \n",
       "2  0.271186  0.007990  0.007812  0.015625  0.007812  0.046512   male  \n",
       "3  0.250000  0.201497  0.007812  0.562500  0.554688  0.247119   male  \n",
       "4  0.266667  0.712812  0.007812  5.484375  5.476562  0.208274   male  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=pd.read_csv(\"Downloads/voice.csv\")\n",
    "ds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aaa7eaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.095798</td>\n",
       "      <td>0.183731</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.224360</td>\n",
       "      <td>0.190936</td>\n",
       "      <td>1.876502</td>\n",
       "      <td>6.604509</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.654196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.209918</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.494271</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>0.194759</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>0.219943</td>\n",
       "      <td>0.176435</td>\n",
       "      <td>1.591065</td>\n",
       "      <td>5.388298</td>\n",
       "      <td>0.950436</td>\n",
       "      <td>0.675470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.172375</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.791360</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>3.585938</td>\n",
       "      <td>0.311002</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859  1.762129   \n",
       "3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193  0.693730   \n",
       "3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936  1.876502   \n",
       "3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435  1.591065   \n",
       "3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756  1.705029   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "3163  6.630383  0.962934  0.763182  ...  0.131884  0.182790  0.083770   \n",
       "3164  2.503954  0.960716  0.709570  ...  0.116221  0.188980  0.034409   \n",
       "3165  6.604509  0.946854  0.654196  ...  0.142056  0.209918  0.039506   \n",
       "3166  5.388298  0.950436  0.675470  ...  0.143659  0.172375  0.034483   \n",
       "3167  5.769115  0.938829  0.601529  ...  0.165509  0.185607  0.062257   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929  female  \n",
       "3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897  female  \n",
       "3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759  female  \n",
       "3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002  female  \n",
       "3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000  female  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8433b94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['meanfreq', 'sd', 'median', 'Q25', 'Q75', 'IQR', 'skew', 'kurt',\n",
       "       'sp.ent', 'sfm', 'mode', 'centroid', 'meanfun', 'minfun', 'maxfun',\n",
       "       'meandom', 'mindom', 'maxdom', 'dfrange', 'modindx', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0cad3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 21)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8d88ee",
   "metadata": {},
   "source": [
    "### 1)Checking the presence of NULL values and HANDLING the NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "942fc279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meanfreq    0\n",
       "sd          0\n",
       "median      0\n",
       "Q25         0\n",
       "Q75         0\n",
       "IQR         0\n",
       "skew        0\n",
       "kurt        0\n",
       "sp.ent      0\n",
       "sfm         0\n",
       "mode        0\n",
       "centroid    0\n",
       "meanfun     0\n",
       "minfun      0\n",
       "maxfun      0\n",
       "meandom     0\n",
       "mindom      0\n",
       "maxdom      0\n",
       "dfrange     0\n",
       "modindx     0\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c49e22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male      1584\n",
      "female    1584\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "m=ds.label.value_counts()\n",
    "print(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8330eb9c",
   "metadata": {},
   "source": [
    "### 2) Depict percentage distribution of label on a piechart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ad0ee9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LABEL PERCENTAGE DISTRIBUTION')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values=ds.label.value_counts()\n",
    "names=[\"MALE\",\"FEMALE\"]\n",
    "plt.pie(values,labels=names,startangle=90)\n",
    "plt.title('LABEL PERCENTAGE DISTRIBUTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d3b4eb",
   "metadata": {},
   "source": [
    "values=ds.label.value_counts()\n",
    "names=[\"MALE\",\"FEMALE\"]\n",
    "plt.pie(values,labels=names)\n",
    "plt.title('LABEL PERCENTAGE DISTRIBUTION')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398c7e06",
   "metadata": {},
   "source": [
    "### CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30986e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>meanfreq</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.739039</td>\n",
       "      <td>0.925445</td>\n",
       "      <td>0.911416</td>\n",
       "      <td>0.740997</td>\n",
       "      <td>-0.627605</td>\n",
       "      <td>-0.322327</td>\n",
       "      <td>-0.316036</td>\n",
       "      <td>-0.601203</td>\n",
       "      <td>-0.784332</td>\n",
       "      <td>0.687715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460844</td>\n",
       "      <td>0.383937</td>\n",
       "      <td>0.274004</td>\n",
       "      <td>0.536666</td>\n",
       "      <td>0.229261</td>\n",
       "      <td>0.519528</td>\n",
       "      <td>0.515570</td>\n",
       "      <td>-0.216979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sd</th>\n",
       "      <td>-0.739039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.562603</td>\n",
       "      <td>-0.846931</td>\n",
       "      <td>-0.161076</td>\n",
       "      <td>0.874660</td>\n",
       "      <td>0.314597</td>\n",
       "      <td>0.346241</td>\n",
       "      <td>0.716620</td>\n",
       "      <td>0.838086</td>\n",
       "      <td>-0.529150</td>\n",
       "      <td>-0.739039</td>\n",
       "      <td>-0.466281</td>\n",
       "      <td>-0.345609</td>\n",
       "      <td>-0.129662</td>\n",
       "      <td>-0.482726</td>\n",
       "      <td>-0.357667</td>\n",
       "      <td>-0.482278</td>\n",
       "      <td>-0.475999</td>\n",
       "      <td>0.122660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>0.925445</td>\n",
       "      <td>-0.562603</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.774922</td>\n",
       "      <td>0.731849</td>\n",
       "      <td>-0.477352</td>\n",
       "      <td>-0.257407</td>\n",
       "      <td>-0.243382</td>\n",
       "      <td>-0.502005</td>\n",
       "      <td>-0.661690</td>\n",
       "      <td>0.677433</td>\n",
       "      <td>0.925445</td>\n",
       "      <td>0.414909</td>\n",
       "      <td>0.337602</td>\n",
       "      <td>0.251328</td>\n",
       "      <td>0.455943</td>\n",
       "      <td>0.191169</td>\n",
       "      <td>0.438919</td>\n",
       "      <td>0.435621</td>\n",
       "      <td>-0.213298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q25</th>\n",
       "      <td>0.911416</td>\n",
       "      <td>-0.846931</td>\n",
       "      <td>0.774922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.477140</td>\n",
       "      <td>-0.874189</td>\n",
       "      <td>-0.319475</td>\n",
       "      <td>-0.350182</td>\n",
       "      <td>-0.648126</td>\n",
       "      <td>-0.766875</td>\n",
       "      <td>0.591277</td>\n",
       "      <td>0.911416</td>\n",
       "      <td>0.545035</td>\n",
       "      <td>0.320994</td>\n",
       "      <td>0.199841</td>\n",
       "      <td>0.467403</td>\n",
       "      <td>0.302255</td>\n",
       "      <td>0.459683</td>\n",
       "      <td>0.454394</td>\n",
       "      <td>-0.141377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q75</th>\n",
       "      <td>0.740997</td>\n",
       "      <td>-0.161076</td>\n",
       "      <td>0.731849</td>\n",
       "      <td>0.477140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009636</td>\n",
       "      <td>-0.206339</td>\n",
       "      <td>-0.148881</td>\n",
       "      <td>-0.174905</td>\n",
       "      <td>-0.378198</td>\n",
       "      <td>0.486857</td>\n",
       "      <td>0.740997</td>\n",
       "      <td>0.155091</td>\n",
       "      <td>0.258002</td>\n",
       "      <td>0.285584</td>\n",
       "      <td>0.359181</td>\n",
       "      <td>-0.023750</td>\n",
       "      <td>0.335114</td>\n",
       "      <td>0.335648</td>\n",
       "      <td>-0.216475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IQR</th>\n",
       "      <td>-0.627605</td>\n",
       "      <td>0.874660</td>\n",
       "      <td>-0.477352</td>\n",
       "      <td>-0.874189</td>\n",
       "      <td>0.009636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.249497</td>\n",
       "      <td>0.316185</td>\n",
       "      <td>0.640813</td>\n",
       "      <td>0.663601</td>\n",
       "      <td>-0.403764</td>\n",
       "      <td>-0.627605</td>\n",
       "      <td>-0.534462</td>\n",
       "      <td>-0.222680</td>\n",
       "      <td>-0.069588</td>\n",
       "      <td>-0.333362</td>\n",
       "      <td>-0.357037</td>\n",
       "      <td>-0.337877</td>\n",
       "      <td>-0.331563</td>\n",
       "      <td>0.041252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skew</th>\n",
       "      <td>-0.322327</td>\n",
       "      <td>0.314597</td>\n",
       "      <td>-0.257407</td>\n",
       "      <td>-0.319475</td>\n",
       "      <td>-0.206339</td>\n",
       "      <td>0.249497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977020</td>\n",
       "      <td>-0.195459</td>\n",
       "      <td>0.079694</td>\n",
       "      <td>-0.434859</td>\n",
       "      <td>-0.322327</td>\n",
       "      <td>-0.167668</td>\n",
       "      <td>-0.216954</td>\n",
       "      <td>-0.080861</td>\n",
       "      <td>-0.336848</td>\n",
       "      <td>-0.061608</td>\n",
       "      <td>-0.305651</td>\n",
       "      <td>-0.304640</td>\n",
       "      <td>-0.169325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kurt</th>\n",
       "      <td>-0.316036</td>\n",
       "      <td>0.346241</td>\n",
       "      <td>-0.243382</td>\n",
       "      <td>-0.350182</td>\n",
       "      <td>-0.148881</td>\n",
       "      <td>0.316185</td>\n",
       "      <td>0.977020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.127644</td>\n",
       "      <td>0.109884</td>\n",
       "      <td>-0.406722</td>\n",
       "      <td>-0.316036</td>\n",
       "      <td>-0.194560</td>\n",
       "      <td>-0.203201</td>\n",
       "      <td>-0.045667</td>\n",
       "      <td>-0.303234</td>\n",
       "      <td>-0.103313</td>\n",
       "      <td>-0.274500</td>\n",
       "      <td>-0.272729</td>\n",
       "      <td>-0.205539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp.ent</th>\n",
       "      <td>-0.601203</td>\n",
       "      <td>0.716620</td>\n",
       "      <td>-0.502005</td>\n",
       "      <td>-0.648126</td>\n",
       "      <td>-0.174905</td>\n",
       "      <td>0.640813</td>\n",
       "      <td>-0.195459</td>\n",
       "      <td>-0.127644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866411</td>\n",
       "      <td>-0.325298</td>\n",
       "      <td>-0.601203</td>\n",
       "      <td>-0.513194</td>\n",
       "      <td>-0.305826</td>\n",
       "      <td>-0.120738</td>\n",
       "      <td>-0.293562</td>\n",
       "      <td>-0.294869</td>\n",
       "      <td>-0.324253</td>\n",
       "      <td>-0.319054</td>\n",
       "      <td>0.198074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sfm</th>\n",
       "      <td>-0.784332</td>\n",
       "      <td>0.838086</td>\n",
       "      <td>-0.661690</td>\n",
       "      <td>-0.766875</td>\n",
       "      <td>-0.378198</td>\n",
       "      <td>0.663601</td>\n",
       "      <td>0.079694</td>\n",
       "      <td>0.109884</td>\n",
       "      <td>0.866411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.485913</td>\n",
       "      <td>-0.784332</td>\n",
       "      <td>-0.421066</td>\n",
       "      <td>-0.362100</td>\n",
       "      <td>-0.192369</td>\n",
       "      <td>-0.428442</td>\n",
       "      <td>-0.289593</td>\n",
       "      <td>-0.436649</td>\n",
       "      <td>-0.431580</td>\n",
       "      <td>0.211477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mode</th>\n",
       "      <td>0.687715</td>\n",
       "      <td>-0.529150</td>\n",
       "      <td>0.677433</td>\n",
       "      <td>0.591277</td>\n",
       "      <td>0.486857</td>\n",
       "      <td>-0.403764</td>\n",
       "      <td>-0.434859</td>\n",
       "      <td>-0.406722</td>\n",
       "      <td>-0.325298</td>\n",
       "      <td>-0.485913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687715</td>\n",
       "      <td>0.324771</td>\n",
       "      <td>0.385467</td>\n",
       "      <td>0.172329</td>\n",
       "      <td>0.491479</td>\n",
       "      <td>0.198150</td>\n",
       "      <td>0.477187</td>\n",
       "      <td>0.473775</td>\n",
       "      <td>-0.182344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>centroid</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.739039</td>\n",
       "      <td>0.925445</td>\n",
       "      <td>0.911416</td>\n",
       "      <td>0.740997</td>\n",
       "      <td>-0.627605</td>\n",
       "      <td>-0.322327</td>\n",
       "      <td>-0.316036</td>\n",
       "      <td>-0.601203</td>\n",
       "      <td>-0.784332</td>\n",
       "      <td>0.687715</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.460844</td>\n",
       "      <td>0.383937</td>\n",
       "      <td>0.274004</td>\n",
       "      <td>0.536666</td>\n",
       "      <td>0.229261</td>\n",
       "      <td>0.519528</td>\n",
       "      <td>0.515570</td>\n",
       "      <td>-0.216979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanfun</th>\n",
       "      <td>0.460844</td>\n",
       "      <td>-0.466281</td>\n",
       "      <td>0.414909</td>\n",
       "      <td>0.545035</td>\n",
       "      <td>0.155091</td>\n",
       "      <td>-0.534462</td>\n",
       "      <td>-0.167668</td>\n",
       "      <td>-0.194560</td>\n",
       "      <td>-0.513194</td>\n",
       "      <td>-0.421066</td>\n",
       "      <td>0.324771</td>\n",
       "      <td>0.460844</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.339387</td>\n",
       "      <td>0.311950</td>\n",
       "      <td>0.270840</td>\n",
       "      <td>0.162163</td>\n",
       "      <td>0.277982</td>\n",
       "      <td>0.275154</td>\n",
       "      <td>-0.054858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minfun</th>\n",
       "      <td>0.383937</td>\n",
       "      <td>-0.345609</td>\n",
       "      <td>0.337602</td>\n",
       "      <td>0.320994</td>\n",
       "      <td>0.258002</td>\n",
       "      <td>-0.222680</td>\n",
       "      <td>-0.216954</td>\n",
       "      <td>-0.203201</td>\n",
       "      <td>-0.305826</td>\n",
       "      <td>-0.362100</td>\n",
       "      <td>0.385467</td>\n",
       "      <td>0.383937</td>\n",
       "      <td>0.339387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.213987</td>\n",
       "      <td>0.375979</td>\n",
       "      <td>0.082015</td>\n",
       "      <td>0.317860</td>\n",
       "      <td>0.316486</td>\n",
       "      <td>0.002042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxfun</th>\n",
       "      <td>0.274004</td>\n",
       "      <td>-0.129662</td>\n",
       "      <td>0.251328</td>\n",
       "      <td>0.199841</td>\n",
       "      <td>0.285584</td>\n",
       "      <td>-0.069588</td>\n",
       "      <td>-0.080861</td>\n",
       "      <td>-0.045667</td>\n",
       "      <td>-0.120738</td>\n",
       "      <td>-0.192369</td>\n",
       "      <td>0.172329</td>\n",
       "      <td>0.274004</td>\n",
       "      <td>0.311950</td>\n",
       "      <td>0.213987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.337553</td>\n",
       "      <td>-0.243426</td>\n",
       "      <td>0.355390</td>\n",
       "      <td>0.359880</td>\n",
       "      <td>-0.363029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meandom</th>\n",
       "      <td>0.536666</td>\n",
       "      <td>-0.482726</td>\n",
       "      <td>0.455943</td>\n",
       "      <td>0.467403</td>\n",
       "      <td>0.359181</td>\n",
       "      <td>-0.333362</td>\n",
       "      <td>-0.336848</td>\n",
       "      <td>-0.303234</td>\n",
       "      <td>-0.293562</td>\n",
       "      <td>-0.428442</td>\n",
       "      <td>0.491479</td>\n",
       "      <td>0.536666</td>\n",
       "      <td>0.270840</td>\n",
       "      <td>0.375979</td>\n",
       "      <td>0.337553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099656</td>\n",
       "      <td>0.812838</td>\n",
       "      <td>0.811304</td>\n",
       "      <td>-0.180954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mindom</th>\n",
       "      <td>0.229261</td>\n",
       "      <td>-0.357667</td>\n",
       "      <td>0.191169</td>\n",
       "      <td>0.302255</td>\n",
       "      <td>-0.023750</td>\n",
       "      <td>-0.357037</td>\n",
       "      <td>-0.061608</td>\n",
       "      <td>-0.103313</td>\n",
       "      <td>-0.294869</td>\n",
       "      <td>-0.289593</td>\n",
       "      <td>0.198150</td>\n",
       "      <td>0.229261</td>\n",
       "      <td>0.162163</td>\n",
       "      <td>0.082015</td>\n",
       "      <td>-0.243426</td>\n",
       "      <td>0.099656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.200212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxdom</th>\n",
       "      <td>0.519528</td>\n",
       "      <td>-0.482278</td>\n",
       "      <td>0.438919</td>\n",
       "      <td>0.459683</td>\n",
       "      <td>0.335114</td>\n",
       "      <td>-0.337877</td>\n",
       "      <td>-0.305651</td>\n",
       "      <td>-0.274500</td>\n",
       "      <td>-0.324253</td>\n",
       "      <td>-0.436649</td>\n",
       "      <td>0.477187</td>\n",
       "      <td>0.519528</td>\n",
       "      <td>0.277982</td>\n",
       "      <td>0.317860</td>\n",
       "      <td>0.355390</td>\n",
       "      <td>0.812838</td>\n",
       "      <td>0.026640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>-0.425531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfrange</th>\n",
       "      <td>0.515570</td>\n",
       "      <td>-0.475999</td>\n",
       "      <td>0.435621</td>\n",
       "      <td>0.454394</td>\n",
       "      <td>0.335648</td>\n",
       "      <td>-0.331563</td>\n",
       "      <td>-0.304640</td>\n",
       "      <td>-0.272729</td>\n",
       "      <td>-0.319054</td>\n",
       "      <td>-0.431580</td>\n",
       "      <td>0.473775</td>\n",
       "      <td>0.515570</td>\n",
       "      <td>0.275154</td>\n",
       "      <td>0.316486</td>\n",
       "      <td>0.359880</td>\n",
       "      <td>0.811304</td>\n",
       "      <td>0.008666</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.429266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modindx</th>\n",
       "      <td>-0.216979</td>\n",
       "      <td>0.122660</td>\n",
       "      <td>-0.213298</td>\n",
       "      <td>-0.141377</td>\n",
       "      <td>-0.216475</td>\n",
       "      <td>0.041252</td>\n",
       "      <td>-0.169325</td>\n",
       "      <td>-0.205539</td>\n",
       "      <td>0.198074</td>\n",
       "      <td>0.211477</td>\n",
       "      <td>-0.182344</td>\n",
       "      <td>-0.216979</td>\n",
       "      <td>-0.054858</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>-0.363029</td>\n",
       "      <td>-0.180954</td>\n",
       "      <td>0.200212</td>\n",
       "      <td>-0.425531</td>\n",
       "      <td>-0.429266</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          meanfreq        sd    median       Q25       Q75       IQR  \\\n",
       "meanfreq  1.000000 -0.739039  0.925445  0.911416  0.740997 -0.627605   \n",
       "sd       -0.739039  1.000000 -0.562603 -0.846931 -0.161076  0.874660   \n",
       "median    0.925445 -0.562603  1.000000  0.774922  0.731849 -0.477352   \n",
       "Q25       0.911416 -0.846931  0.774922  1.000000  0.477140 -0.874189   \n",
       "Q75       0.740997 -0.161076  0.731849  0.477140  1.000000  0.009636   \n",
       "IQR      -0.627605  0.874660 -0.477352 -0.874189  0.009636  1.000000   \n",
       "skew     -0.322327  0.314597 -0.257407 -0.319475 -0.206339  0.249497   \n",
       "kurt     -0.316036  0.346241 -0.243382 -0.350182 -0.148881  0.316185   \n",
       "sp.ent   -0.601203  0.716620 -0.502005 -0.648126 -0.174905  0.640813   \n",
       "sfm      -0.784332  0.838086 -0.661690 -0.766875 -0.378198  0.663601   \n",
       "mode      0.687715 -0.529150  0.677433  0.591277  0.486857 -0.403764   \n",
       "centroid  1.000000 -0.739039  0.925445  0.911416  0.740997 -0.627605   \n",
       "meanfun   0.460844 -0.466281  0.414909  0.545035  0.155091 -0.534462   \n",
       "minfun    0.383937 -0.345609  0.337602  0.320994  0.258002 -0.222680   \n",
       "maxfun    0.274004 -0.129662  0.251328  0.199841  0.285584 -0.069588   \n",
       "meandom   0.536666 -0.482726  0.455943  0.467403  0.359181 -0.333362   \n",
       "mindom    0.229261 -0.357667  0.191169  0.302255 -0.023750 -0.357037   \n",
       "maxdom    0.519528 -0.482278  0.438919  0.459683  0.335114 -0.337877   \n",
       "dfrange   0.515570 -0.475999  0.435621  0.454394  0.335648 -0.331563   \n",
       "modindx  -0.216979  0.122660 -0.213298 -0.141377 -0.216475  0.041252   \n",
       "\n",
       "              skew      kurt    sp.ent       sfm      mode  centroid  \\\n",
       "meanfreq -0.322327 -0.316036 -0.601203 -0.784332  0.687715  1.000000   \n",
       "sd        0.314597  0.346241  0.716620  0.838086 -0.529150 -0.739039   \n",
       "median   -0.257407 -0.243382 -0.502005 -0.661690  0.677433  0.925445   \n",
       "Q25      -0.319475 -0.350182 -0.648126 -0.766875  0.591277  0.911416   \n",
       "Q75      -0.206339 -0.148881 -0.174905 -0.378198  0.486857  0.740997   \n",
       "IQR       0.249497  0.316185  0.640813  0.663601 -0.403764 -0.627605   \n",
       "skew      1.000000  0.977020 -0.195459  0.079694 -0.434859 -0.322327   \n",
       "kurt      0.977020  1.000000 -0.127644  0.109884 -0.406722 -0.316036   \n",
       "sp.ent   -0.195459 -0.127644  1.000000  0.866411 -0.325298 -0.601203   \n",
       "sfm       0.079694  0.109884  0.866411  1.000000 -0.485913 -0.784332   \n",
       "mode     -0.434859 -0.406722 -0.325298 -0.485913  1.000000  0.687715   \n",
       "centroid -0.322327 -0.316036 -0.601203 -0.784332  0.687715  1.000000   \n",
       "meanfun  -0.167668 -0.194560 -0.513194 -0.421066  0.324771  0.460844   \n",
       "minfun   -0.216954 -0.203201 -0.305826 -0.362100  0.385467  0.383937   \n",
       "maxfun   -0.080861 -0.045667 -0.120738 -0.192369  0.172329  0.274004   \n",
       "meandom  -0.336848 -0.303234 -0.293562 -0.428442  0.491479  0.536666   \n",
       "mindom   -0.061608 -0.103313 -0.294869 -0.289593  0.198150  0.229261   \n",
       "maxdom   -0.305651 -0.274500 -0.324253 -0.436649  0.477187  0.519528   \n",
       "dfrange  -0.304640 -0.272729 -0.319054 -0.431580  0.473775  0.515570   \n",
       "modindx  -0.169325 -0.205539  0.198074  0.211477 -0.182344 -0.216979   \n",
       "\n",
       "           meanfun    minfun    maxfun   meandom    mindom    maxdom  \\\n",
       "meanfreq  0.460844  0.383937  0.274004  0.536666  0.229261  0.519528   \n",
       "sd       -0.466281 -0.345609 -0.129662 -0.482726 -0.357667 -0.482278   \n",
       "median    0.414909  0.337602  0.251328  0.455943  0.191169  0.438919   \n",
       "Q25       0.545035  0.320994  0.199841  0.467403  0.302255  0.459683   \n",
       "Q75       0.155091  0.258002  0.285584  0.359181 -0.023750  0.335114   \n",
       "IQR      -0.534462 -0.222680 -0.069588 -0.333362 -0.357037 -0.337877   \n",
       "skew     -0.167668 -0.216954 -0.080861 -0.336848 -0.061608 -0.305651   \n",
       "kurt     -0.194560 -0.203201 -0.045667 -0.303234 -0.103313 -0.274500   \n",
       "sp.ent   -0.513194 -0.305826 -0.120738 -0.293562 -0.294869 -0.324253   \n",
       "sfm      -0.421066 -0.362100 -0.192369 -0.428442 -0.289593 -0.436649   \n",
       "mode      0.324771  0.385467  0.172329  0.491479  0.198150  0.477187   \n",
       "centroid  0.460844  0.383937  0.274004  0.536666  0.229261  0.519528   \n",
       "meanfun   1.000000  0.339387  0.311950  0.270840  0.162163  0.277982   \n",
       "minfun    0.339387  1.000000  0.213987  0.375979  0.082015  0.317860   \n",
       "maxfun    0.311950  0.213987  1.000000  0.337553 -0.243426  0.355390   \n",
       "meandom   0.270840  0.375979  0.337553  1.000000  0.099656  0.812838   \n",
       "mindom    0.162163  0.082015 -0.243426  0.099656  1.000000  0.026640   \n",
       "maxdom    0.277982  0.317860  0.355390  0.812838  0.026640  1.000000   \n",
       "dfrange   0.275154  0.316486  0.359880  0.811304  0.008666  0.999838   \n",
       "modindx  -0.054858  0.002042 -0.363029 -0.180954  0.200212 -0.425531   \n",
       "\n",
       "           dfrange   modindx  \n",
       "meanfreq  0.515570 -0.216979  \n",
       "sd       -0.475999  0.122660  \n",
       "median    0.435621 -0.213298  \n",
       "Q25       0.454394 -0.141377  \n",
       "Q75       0.335648 -0.216475  \n",
       "IQR      -0.331563  0.041252  \n",
       "skew     -0.304640 -0.169325  \n",
       "kurt     -0.272729 -0.205539  \n",
       "sp.ent   -0.319054  0.198074  \n",
       "sfm      -0.431580  0.211477  \n",
       "mode      0.473775 -0.182344  \n",
       "centroid  0.515570 -0.216979  \n",
       "meanfun   0.275154 -0.054858  \n",
       "minfun    0.316486  0.002042  \n",
       "maxfun    0.359880 -0.363029  \n",
       "meandom   0.811304 -0.180954  \n",
       "mindom    0.008666  0.200212  \n",
       "maxdom    0.999838 -0.425531  \n",
       "dfrange   1.000000 -0.429266  \n",
       "modindx  -0.429266  1.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30016f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "3163    1\n",
       "3164    1\n",
       "3165    1\n",
       "3166    1\n",
       "3167    1\n",
       "Name: label, Length: 3168, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.label= [ 1 if each == \"female\" else 0  for each in ds.label ]\n",
    "ds.label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c74cb9a",
   "metadata": {},
   "source": [
    "### 3)Considering all the features as indepedent feature and label as dependent feature, split the dataset training and testing data with test size = 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44129887",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=ds.drop(['label'],axis='columns')\n",
    "y=ds.label.values\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "519684c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2534, 20)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8403d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(634, 20)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f062e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>0.209285</td>\n",
       "      <td>0.035755</td>\n",
       "      <td>0.208437</td>\n",
       "      <td>0.186223</td>\n",
       "      <td>0.235705</td>\n",
       "      <td>0.049482</td>\n",
       "      <td>1.856039</td>\n",
       "      <td>6.939422</td>\n",
       "      <td>0.887245</td>\n",
       "      <td>0.175863</td>\n",
       "      <td>0.193007</td>\n",
       "      <td>0.209285</td>\n",
       "      <td>0.144926</td>\n",
       "      <td>0.043491</td>\n",
       "      <td>0.277358</td>\n",
       "      <td>1.289301</td>\n",
       "      <td>0.021533</td>\n",
       "      <td>8.311816</td>\n",
       "      <td>8.290283</td>\n",
       "      <td>0.107427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.194606</td>\n",
       "      <td>0.059381</td>\n",
       "      <td>0.217306</td>\n",
       "      <td>0.133872</td>\n",
       "      <td>0.241818</td>\n",
       "      <td>0.107946</td>\n",
       "      <td>1.693084</td>\n",
       "      <td>6.290157</td>\n",
       "      <td>0.901328</td>\n",
       "      <td>0.384840</td>\n",
       "      <td>0.217306</td>\n",
       "      <td>0.194606</td>\n",
       "      <td>0.110265</td>\n",
       "      <td>0.044077</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.592285</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>4.304688</td>\n",
       "      <td>4.171875</td>\n",
       "      <td>0.158302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.153063</td>\n",
       "      <td>0.059616</td>\n",
       "      <td>0.137857</td>\n",
       "      <td>0.100177</td>\n",
       "      <td>0.203288</td>\n",
       "      <td>0.103110</td>\n",
       "      <td>2.744697</td>\n",
       "      <td>12.004652</td>\n",
       "      <td>0.902960</td>\n",
       "      <td>0.424031</td>\n",
       "      <td>0.098598</td>\n",
       "      <td>0.153063</td>\n",
       "      <td>0.109356</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.561988</td>\n",
       "      <td>0.102539</td>\n",
       "      <td>0.810547</td>\n",
       "      <td>0.708008</td>\n",
       "      <td>0.587586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>0.201464</td>\n",
       "      <td>0.047455</td>\n",
       "      <td>0.203636</td>\n",
       "      <td>0.161690</td>\n",
       "      <td>0.242356</td>\n",
       "      <td>0.080666</td>\n",
       "      <td>1.025141</td>\n",
       "      <td>3.273490</td>\n",
       "      <td>0.906194</td>\n",
       "      <td>0.280811</td>\n",
       "      <td>0.261357</td>\n",
       "      <td>0.201464</td>\n",
       "      <td>0.166031</td>\n",
       "      <td>0.056206</td>\n",
       "      <td>0.277457</td>\n",
       "      <td>1.409531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>8.765625</td>\n",
       "      <td>8.742188</td>\n",
       "      <td>0.122048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>0.176352</td>\n",
       "      <td>0.050410</td>\n",
       "      <td>0.191790</td>\n",
       "      <td>0.127593</td>\n",
       "      <td>0.215803</td>\n",
       "      <td>0.088210</td>\n",
       "      <td>1.604280</td>\n",
       "      <td>5.829200</td>\n",
       "      <td>0.917414</td>\n",
       "      <td>0.229564</td>\n",
       "      <td>0.198994</td>\n",
       "      <td>0.176352</td>\n",
       "      <td>0.117233</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.688519</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.679688</td>\n",
       "      <td>5.671875</td>\n",
       "      <td>0.121488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "3113  0.209285  0.035755  0.208437  0.186223  0.235705  0.049482  1.856039   \n",
       "423   0.194606  0.059381  0.217306  0.133872  0.241818  0.107946  1.693084   \n",
       "684   0.153063  0.059616  0.137857  0.100177  0.203288  0.103110  2.744697   \n",
       "2683  0.201464  0.047455  0.203636  0.161690  0.242356  0.080666  1.025141   \n",
       "670   0.176352  0.050410  0.191790  0.127593  0.215803  0.088210  1.604280   \n",
       "\n",
       "           kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n",
       "3113   6.939422  0.887245  0.175863  0.193007  0.209285  0.144926  0.043491   \n",
       "423    6.290157  0.901328  0.384840  0.217306  0.194606  0.110265  0.044077   \n",
       "684   12.004652  0.902960  0.424031  0.098598  0.153063  0.109356  0.036232   \n",
       "2683   3.273490  0.906194  0.280811  0.261357  0.201464  0.166031  0.056206   \n",
       "670    5.829200  0.917414  0.229564  0.198994  0.176352  0.117233  0.017937   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx  \n",
       "3113  0.277358  1.289301  0.021533  8.311816  8.290283  0.107427  \n",
       "423   0.166667  0.592285  0.132812  4.304688  4.171875  0.158302  \n",
       "684   0.270270  0.561988  0.102539  0.810547  0.708008  0.587586  \n",
       "2683  0.277457  1.409531  0.023438  8.765625  8.742188  0.122048  \n",
       "670   0.250000  0.688519  0.007812  5.679688  5.671875  0.121488  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd8495ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>mode</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.167705</td>\n",
       "      <td>0.070774</td>\n",
       "      <td>0.179442</td>\n",
       "      <td>0.097629</td>\n",
       "      <td>0.231771</td>\n",
       "      <td>0.134142</td>\n",
       "      <td>17.948488</td>\n",
       "      <td>416.183638</td>\n",
       "      <td>0.921257</td>\n",
       "      <td>0.519320</td>\n",
       "      <td>0.059944</td>\n",
       "      <td>0.167705</td>\n",
       "      <td>0.081219</td>\n",
       "      <td>0.015889</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.073828</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.037270</td>\n",
       "      <td>0.230680</td>\n",
       "      <td>0.201553</td>\n",
       "      <td>0.253981</td>\n",
       "      <td>0.052427</td>\n",
       "      <td>1.615708</td>\n",
       "      <td>4.969158</td>\n",
       "      <td>0.886571</td>\n",
       "      <td>0.158442</td>\n",
       "      <td>0.207249</td>\n",
       "      <td>0.223077</td>\n",
       "      <td>0.144216</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.275625</td>\n",
       "      <td>1.133599</td>\n",
       "      <td>0.021533</td>\n",
       "      <td>8.397949</td>\n",
       "      <td>8.376416</td>\n",
       "      <td>0.115553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0.190837</td>\n",
       "      <td>0.061080</td>\n",
       "      <td>0.212616</td>\n",
       "      <td>0.131839</td>\n",
       "      <td>0.240239</td>\n",
       "      <td>0.108401</td>\n",
       "      <td>1.445146</td>\n",
       "      <td>5.127113</td>\n",
       "      <td>0.921104</td>\n",
       "      <td>0.479038</td>\n",
       "      <td>0.237728</td>\n",
       "      <td>0.190837</td>\n",
       "      <td>0.110244</td>\n",
       "      <td>0.041026</td>\n",
       "      <td>0.246154</td>\n",
       "      <td>0.584635</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3.570312</td>\n",
       "      <td>3.445312</td>\n",
       "      <td>0.164866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>0.205177</td>\n",
       "      <td>0.046889</td>\n",
       "      <td>0.212767</td>\n",
       "      <td>0.204628</td>\n",
       "      <td>0.227744</td>\n",
       "      <td>0.023116</td>\n",
       "      <td>3.695067</td>\n",
       "      <td>18.903910</td>\n",
       "      <td>0.849017</td>\n",
       "      <td>0.291601</td>\n",
       "      <td>0.210326</td>\n",
       "      <td>0.205177</td>\n",
       "      <td>0.201443</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.405273</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.830078</td>\n",
       "      <td>0.825195</td>\n",
       "      <td>0.447616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>0.238831</td>\n",
       "      <td>0.030060</td>\n",
       "      <td>0.243616</td>\n",
       "      <td>0.220942</td>\n",
       "      <td>0.261017</td>\n",
       "      <td>0.040075</td>\n",
       "      <td>1.918328</td>\n",
       "      <td>6.120897</td>\n",
       "      <td>0.814822</td>\n",
       "      <td>0.118336</td>\n",
       "      <td>0.261544</td>\n",
       "      <td>0.238831</td>\n",
       "      <td>0.187539</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.277457</td>\n",
       "      <td>1.326923</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>9.773438</td>\n",
       "      <td>9.750000</td>\n",
       "      <td>0.137525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "125   0.167705  0.070774  0.179442  0.097629  0.231771  0.134142  17.948488   \n",
       "3117  0.223077  0.037270  0.230680  0.201553  0.253981  0.052427   1.615708   \n",
       "418   0.190837  0.061080  0.212616  0.131839  0.240239  0.108401   1.445146   \n",
       "3013  0.205177  0.046889  0.212767  0.204628  0.227744  0.023116   3.695067   \n",
       "2594  0.238831  0.030060  0.243616  0.220942  0.261017  0.040075   1.918328   \n",
       "\n",
       "            kurt    sp.ent       sfm      mode  centroid   meanfun    minfun  \\\n",
       "125   416.183638  0.921257  0.519320  0.059944  0.167705  0.081219  0.015889   \n",
       "3117    4.969158  0.886571  0.158442  0.207249  0.223077  0.144216  0.043577   \n",
       "418     5.127113  0.921104  0.479038  0.237728  0.190837  0.110244  0.041026   \n",
       "3013   18.903910  0.849017  0.291601  0.210326  0.205177  0.201443  0.063694   \n",
       "2594    6.120897  0.814822  0.118336  0.261544  0.238831  0.187539  0.047619   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx  \n",
       "125   0.271186  0.073828  0.070312  0.210938  0.140625  0.051282  \n",
       "3117  0.275625  1.133599  0.021533  8.397949  8.376416  0.115553  \n",
       "418   0.246154  0.584635  0.125000  3.570312  3.445312  0.164866  \n",
       "3013  0.250000  0.405273  0.004883  0.830078  0.825195  0.447616  \n",
       "2594  0.277457  1.326923  0.023438  9.773438  9.750000  0.137525  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2b28ae",
   "metadata": {},
   "source": [
    "## 4)Apply the following classifier models on training dataset and generate predictions for the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e05fb0d",
   "metadata": {},
   "source": [
    "### a) Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2b467b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Decision Tree Classifier is   0.9684542586750788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "deci_tree = DecisionTreeClassifier()\n",
    "deci_tree.fit(x_train,y_train)\n",
    "print(\"Score of Decision Tree Classifier is  \",deci_tree.score(x_test,y_test))\n",
    "pred1=deci_tree.predict(x_test)\n",
    "pred1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3819f6ac",
   "metadata": {},
   "source": [
    "### b. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8137dae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of Random Forest Classifier is   0.9794952681388013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "ran_forest = RandomForestClassifier()\n",
    "ran_forest.fit(x_train,y_train)\n",
    "print(\"Score of Random Forest Classifier is  \",ran_forest.score(x_test,y_test))\n",
    "pred2=ran_forest.predict(x_test)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eecf5c",
   "metadata": {},
   "source": [
    "### c. KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0cd7fd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of KNeighbors Classifier is   0.694006309148265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc=KNeighborsClassifier()\n",
    "knc.fit(x_train,y_train)\n",
    "print(\"Score of KNeighbors Classifier is  \",knc.score(x_test,y_test))\n",
    "pred3=knc.predict(x_test)\n",
    "pred3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bd9573",
   "metadata": {},
   "source": [
    "### d. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1faa5fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of LogisticRegression Classifier is   0.8943217665615142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"Score of LogisticRegression Classifier is  \",lr.score(x_test,y_test))\n",
    "pred4=lr.predict(x_test)\n",
    "pred4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304462b5",
   "metadata": {},
   "source": [
    "### e. SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f16b7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of SVClassifier is   0.6750788643533123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "svc.fit(x_train,y_train)\n",
    "print(\"Score of SVClassifier is  \",svc.score(x_test,y_test))\n",
    "pred5=svc.predict(x_test)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9688719",
   "metadata": {},
   "source": [
    "## 5) CONFUSION MATRIX AND CLASSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "03faa917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e9dfc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(y_test,ypred):\n",
    "    cm=confusion_matrix(y_test,ypred)\n",
    "    print(cm)\n",
    "    print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25950d5",
   "metadata": {},
   "source": [
    "### For Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6e41039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[304  13]\n",
      " [  7 310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       317\n",
      "           1       0.96      0.98      0.97       317\n",
      "\n",
      "    accuracy                           0.97       634\n",
      "   macro avg       0.97      0.97      0.97       634\n",
      "weighted avg       0.97      0.97      0.97       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metrics(y_test,pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666d7fdb",
   "metadata": {},
   "source": [
    "### For Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef0bd329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[308   9]\n",
      " [  4 313]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       317\n",
      "           1       0.97      0.99      0.98       317\n",
      "\n",
      "    accuracy                           0.98       634\n",
      "   macro avg       0.98      0.98      0.98       634\n",
      "weighted avg       0.98      0.98      0.98       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metrics(y_test,pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b90c74",
   "metadata": {},
   "source": [
    "### For KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4bffec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239  78]\n",
      " [116 201]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71       317\n",
      "           1       0.72      0.63      0.67       317\n",
      "\n",
      "    accuracy                           0.69       634\n",
      "   macro avg       0.70      0.69      0.69       634\n",
      "weighted avg       0.70      0.69      0.69       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metrics(y_test,pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e66bc2c",
   "metadata": {},
   "source": [
    "### For Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d6d681ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[305  12]\n",
      " [ 55 262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90       317\n",
      "           1       0.96      0.83      0.89       317\n",
      "\n",
      "    accuracy                           0.89       634\n",
      "   macro avg       0.90      0.89      0.89       634\n",
      "weighted avg       0.90      0.89      0.89       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metrics(y_test,pred4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46f1c7f",
   "metadata": {},
   "source": [
    "### For SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e441ec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[253  64]\n",
      " [142 175]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.80      0.71       317\n",
      "           1       0.73      0.55      0.63       317\n",
      "\n",
      "    accuracy                           0.68       634\n",
      "   macro avg       0.69      0.68      0.67       634\n",
      "weighted avg       0.69      0.68      0.67       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_metrics(y_test,pred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b38cc97",
   "metadata": {},
   "source": [
    "## 6) Report the MODEL with best Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364fa81",
   "metadata": {},
   "source": [
    "####  Decision Tree Classifier and Random Forest Classifier are the models with best accuracy ,whereas Logistic Regression model has good accuracy , KNN Classifier and SVM Classifier models are not with good accuracy.\n",
    "#### Hence, we can conclude that Decision Tree Classifier and Random Forest Classifier are the models that have best accuracy by the help of confusion_matrix and classification report for the given data.So it's better to use these models for best outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
